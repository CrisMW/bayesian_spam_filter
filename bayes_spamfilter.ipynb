{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A spam filter based on the Naive Bayes algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spam messages are a nuissance to consumers, and effective spam filtering represents a real advantage for any service provider. In this project, a dataset of text messages will be used to build a basic spam filter based on the Naive Bayes algorithm.\n",
    "\n",
    "Spam filtering represents a binary classification problem, because messages should either be spam or ham. Bayes theorem allows us to quantify the intensity of a hypothesis based on the observed data like so:\n",
    "<br>![Bayes.png](Bayes.png)\n",
    "\n",
    "Applying Bayes theorem to our problem, we would need to calculate the following items for both spam and ham messages:\n",
    "- The prior, *P*(H). In our case, the frequencies of spam and ham, respectively.\n",
    "- The likelihood, *P*(D | H). In our case, how often each word (D) occurs relative to all the words in spam or ham messages (H), respectively. \n",
    "- *P*(D). In our case, how frequently each word  occurs relative to the words in all messages.\n",
    "\n",
    "Most messages, however, have several words. Following the basic rules of probability, we can obtain the posterior probability of class y (i.e. ham or spam) given features x<sub>1</sub> to x<sub>n</sub> (i.e. words in the message) like so:\n",
    "<br>![Bayes_expanded.png](Bayes_expanded.png)\n",
    "\n",
    "Since the denominator is the same, no matter whether we are trying to calculate P(spam | message) or P(ham | message), we can drop it. Instead, we can rely on proportionality: \n",
    "<br>![Bayes_proportional.png](Bayes_proportional.png)\n",
    "\n",
    "To determine whether a message is spam or ham, we finally need to compare P(spam | message) and P(ham | message). The class with the higher probability should be our output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "\n",
    "msgs = pd.read_csv('data/SMSSpamCollection', sep='\\t', header=None, names=['Label', 'SMS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msgs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     0.865937\n",
       "spam    0.134063\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Frequencies of ham and spam\n",
    "\n",
    "msgs['Label'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomization & Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomizing messages\n",
    "\n",
    "msgs_random = msgs.sample(frac=1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting ~80% of the data for training, ~20% for testing\n",
    "\n",
    "split_index = round(len(msgs_random) * 0.8)\n",
    "msgs_train = msgs_random[:split_index].reset_index(drop=True)\n",
    "msgs_test = msgs_random[split_index:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the train/test split, we should have very similar frequencies of ham and spam in both sets. Otherwise our model may not translate well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     0.86541\n",
       "spam    0.13459\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking frequencies in train\n",
    "\n",
    "msgs_train['Label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     0.868043\n",
       "spam    0.131957\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking frequencies in test\n",
    "\n",
    "msgs_test['Label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simplify our calculations, we will assume that there is no difference between uppercase and lowercase words. We will now:\n",
    "- convert all words to lowercase\n",
    "- replace non-word characters with a space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>yep  by the pretty sculpture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>yes  princess  are you going to make me moan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>welp apparently he retired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>havent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>i forgot 2 ask ü all smth   there s a card on ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham                       yep  by the pretty sculpture\n",
       "1   ham      yes  princess  are you going to make me moan \n",
       "2   ham                         welp apparently he retired\n",
       "3   ham                                            havent \n",
       "4   ham  i forgot 2 ask ü all smth   there s a card on ..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msgs_train_cln = msgs_train.copy()\n",
    "msgs_train_cln['SMS'] = msgs_train_cln['SMS'].str.replace('\\W', ' ')\n",
    "msgs_train_cln['SMS'] = msgs_train_cln['SMS'].str.lower()\n",
    "msgs_train_cln.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to obtain a list of unique words in the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting messages from string to list\n",
    "\n",
    "msgs_train_cln['SMS'] = msgs_train_cln['SMS'].str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7783"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting unique words\n",
    "\n",
    "vocabulary = []\n",
    "for row in msgs_train_cln['SMS']:\n",
    "    for item in row:\n",
    "        vocabulary.append(item)\n",
    "\n",
    "vocabulary = list(set(vocabulary))\n",
    "\n",
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to create a dataframe with messages as rows and words as columns. If a given word appears in a message, the column for that word will have a value of 1 in that rows. For words that do not appear in that message, the corresponding columns will have a value of 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>wth</th>\n",
       "      <th>wright</th>\n",
       "      <th>gods</th>\n",
       "      <th>tap</th>\n",
       "      <th>09058094597</th>\n",
       "      <th>inclu</th>\n",
       "      <th>cool</th>\n",
       "      <th>stifled</th>\n",
       "      <th>...</th>\n",
       "      <th>incorrect</th>\n",
       "      <th>brah</th>\n",
       "      <th>invitation</th>\n",
       "      <th>bslvyl</th>\n",
       "      <th>menu</th>\n",
       "      <th>deciding</th>\n",
       "      <th>against</th>\n",
       "      <th>docks</th>\n",
       "      <th>beer</th>\n",
       "      <th>persevered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yep, by, the, pretty, sculpture]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yes, princess, are, you, going, to, make, me,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>[welp, apparently, he, retired]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[havent]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[i, forgot, 2, ask, ü, all, smth, there, s, a,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS  wth  wright  gods  \\\n",
       "0   ham                  [yep, by, the, pretty, sculpture]    0       0     0   \n",
       "1   ham  [yes, princess, are, you, going, to, make, me,...    0       0     0   \n",
       "2   ham                    [welp, apparently, he, retired]    0       0     0   \n",
       "3   ham                                           [havent]    0       0     0   \n",
       "4   ham  [i, forgot, 2, ask, ü, all, smth, there, s, a,...    0       0     0   \n",
       "\n",
       "   tap  09058094597  inclu  cool  stifled     ...      incorrect  brah  \\\n",
       "0    0            0      0     0        0     ...              0     0   \n",
       "1    0            0      0     0        0     ...              0     0   \n",
       "2    0            0      0     0        0     ...              0     0   \n",
       "3    0            0      0     0        0     ...              0     0   \n",
       "4    0            0      0     0        0     ...              0     0   \n",
       "\n",
       "   invitation  bslvyl  menu  deciding  against  docks  beer  persevered  \n",
       "0           0       0     0         0        0      0     0           0  \n",
       "1           0       0     0         0        0      0     0           0  \n",
       "2           0       0     0         0        0      0     0           0  \n",
       "3           0       0     0         0        0      0     0           0  \n",
       "4           0       0     0         0        0      0     0           0  \n",
       "\n",
       "[5 rows x 7785 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating an all-zero dictionary with words as keys\n",
    "word_counts_per_sms = {word: [0] * len(msgs_train_cln['SMS']) for word in vocabulary}\n",
    "\n",
    "# Populating from dataframe\n",
    "for index, sms in enumerate(msgs_train_cln['SMS']):\n",
    "    for word in sms:\n",
    "        word_counts_per_sms[word][index] += 1\n",
    "        \n",
    "# Converting dictionary to dataframe\n",
    "word_count_df = pd.DataFrame(word_counts_per_sms)\n",
    "\n",
    "# Concatenating original df with tokenized df\n",
    "final_training = pd.concat([msgs_train_cln, word_count_df], axis=1)\n",
    "final_training.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the priors\n",
    "\n",
    "I.e. the frequencies of spam and ham."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "proportions = final_training['Label'].value_counts(normalize = True)\n",
    "p_spam = proportions['spam']\n",
    "p_ham = proportions['ham']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating likelihoods\n",
    "\n",
    "I.e. the frequency of each word in spam (or ham) divided by all the words in spam (or ham) multiplied by all the possible words. We will apply Laplace smoothing (alpha = 1).\n",
    "\n",
    "P(w | spam) = (N<sub>w_spam</sub> + alpha) / (N<sub>spam</sub> + alpha * N<sub>vocabulary</sub>)<br>\n",
    "<br>P(w | ham) = (N<sub>w_ham</sub> + alpha) / (N<sub>ham</sub> + alpha * N<sub>vocabulary</sub>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13458950201884254 0.8654104979811574 15190 57237\n"
     ]
    }
   ],
   "source": [
    "# Number of words in all spam messages\n",
    "train_spam = final_training[final_training['Label'] == 'spam']\n",
    "spam_msg_len = train_spam['SMS'].apply(len)\n",
    "n_spam = spam_msg_len.sum()\n",
    "\n",
    "# Number of words in all ham messages\n",
    "train_ham = final_training[final_training['Label'] == 'ham']\n",
    "ham_msg_len = train_ham['SMS'].apply(len)\n",
    "n_ham = ham_msg_len.sum()\n",
    "\n",
    "# Alpha for laplace smoothing\n",
    "alpha = 1\n",
    "\n",
    "print(p_spam, p_ham, n_spam, n_ham)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populating dictionaries with p_given_spam and p_given_ham for each unique word.\n",
    "\n",
    "p_given_spam = {}\n",
    "p_given_ham = {}\n",
    "\n",
    "for word in vocabulary:\n",
    "    p_given_spam[word] = (train_spam[word].sum() + alpha) / (n_spam + alpha * len(vocabulary))\n",
    "    p_given_ham[word] = (train_ham[word].sum() + alpha) / (n_ham + alpha * len(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00766116745745005\n",
      "0.0007536142725315288\n",
      "0.0004352936055369347\n",
      "0.002522300830513688\n"
     ]
    }
   ],
   "source": [
    "# Printing some examples \n",
    "\n",
    "print(p_given_spam['free'])\n",
    "print(p_given_ham['free'])\n",
    "print(p_given_spam['love'])\n",
    "print(p_given_ham['love'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0000000000000986 0.9999999999999964\n"
     ]
    }
   ],
   "source": [
    "# Checking that likelihoods sum to approx. 1\n",
    "counter_spam = 0 \n",
    "for k, v in p_given_spam.items():\n",
    "    counter_spam += v\n",
    "    \n",
    "counter_ham = 0 \n",
    "for k, v in p_given_ham.items():\n",
    "    counter_ham += v\n",
    "\n",
    "print(counter_spam, counter_ham)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the classifier\n",
    "\n",
    "To classify unseen new messages, we need a function which does several things:\n",
    "- process new messages like the ones in our training set,\n",
    "- use the appripriate priors and likelihoods to calculate unnormalised *P*(ham) and *P*(spam),\n",
    "- compare the two,\n",
    "- and finally return the class with higher probability.\n",
    "\n",
    "If there is a tie between the two, our function should alert us so we can classify it manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def classify(message):\n",
    "    \"\"\"Determines whether it a text message is spam or ham.\n",
    "    Args:\n",
    "        message (str): string containing the message\n",
    "    Returns:\n",
    "        classified (str): 'ham', 'spam' or 'needs human classification'\n",
    "    \"\"\"\n",
    "    # Process message, i.e. replace all non-word characters with a space,\n",
    "    # split message into a list of strings.\n",
    "    message = re.sub('\\W', ' ', message).lower().split()\n",
    "   \n",
    "    # Calculate unnormalised posteriors\n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "    \n",
    "    for word in message:\n",
    "        if word in p_given_spam:\n",
    "            p_spam_given_message *= p_given_spam[word]\n",
    "        if word in p_given_ham:\n",
    "            p_ham_given_message *= p_given_ham[word]\n",
    "    \n",
    "    # Compare the posteriors and return class\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        classified = 'ham'\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        classified = 'spam'\n",
    "    else:\n",
    "        classified = 'unclassified'\n",
    "    return classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spam'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify('WINNER!! This is the secret code to unlock the money: C3421.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ham'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify(\"Sounds good, Tom, then see u there\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate our naive Bayes classifier, we can chose from several metrics like total accuracy, false positives, false negatives etc.<br><br> Which metric we focus on depends on where we see the greatest danger. If we want to avoid users receiving annoying or dangerous spam in their inbox, we should minimise false negatives. If, however, we want to avoid harmless and possibly important emails ending up in the spam folder, we should keep false positives down.<br><br>\n",
    "This choice depends mainly on who the users of our service are. Businesses and large organisations, for example, have different needs than consumers. For now, let's focus on how well the model developed here detects actual spam. This can be captured by three metrics:\n",
    "\n",
    "- <b>True-positive rate (aka recall, TPR)</b>: # true positives / (# true positives + # false negatives)\n",
    "- <b>Precision</b>: # true positives / (# true positives + # false positives)\n",
    "- <b>F<sub>1</sub> score</b>: 2 × Preicison × TPR / (Precision + TPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions\n",
    "msgs_test['Predicted'] = msgs_test['SMS'].apply(classify)\n",
    "\n",
    "# Isolating predictions and true labels into new df\n",
    "cols = ['Label', 'Predicted']\n",
    "msgs_boolean = msgs_test[cols]\n",
    "\n",
    "# To make calculations faster, 'ham' will be converted to 0, 'spam' to 1, 'unclassified' to 0\n",
    "mapping_dict = {'ham':0, 'spam':1, 'unclassified':0}\n",
    "msgs_boolean = msgs_test[cols].applymap(lambda x: mapping_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9883303411131059\n"
     ]
    }
   ],
   "source": [
    "# Calculating total accuracy\n",
    "total_accuracy = (msgs_boolean['Label'] == msgs_boolean['Predicted']).sum() / len(msgs_boolean)\n",
    "\n",
    "print(total_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tpr': 0.9455782312925171, 'precision': 0.9652777777777778, 'f1_score': 0.9553264604810997}\n"
     ]
    }
   ],
   "source": [
    "metrics = {}\n",
    "\n",
    "# Calculating true positives\n",
    "true_pos = ((msgs_boolean.Label == 1) & (msgs_boolean.Predicted == 1)).sum()\n",
    "\n",
    "# Calculating false negatives\n",
    "false_neg = ((msgs_boolean.Label == 1) & (msgs_boolean.Predicted == 0)).sum()\n",
    "\n",
    "# Calculating false positives\n",
    "false_pos = ((msgs_boolean.Label == 0) & (msgs_boolean.Predicted == 1)).sum()\n",
    "\n",
    "# Calculating true positive rate (recall)\n",
    "tpr = true_pos / (true_pos + false_neg)\n",
    "metrics['tpr'] = tpr\n",
    "\n",
    "# Calculating precision\n",
    "precision = true_pos / (true_pos + false_pos)\n",
    "metrics['precision'] = precision\n",
    "\n",
    "# Calculating precision\n",
    "f1_score = 2 * precision * tpr / (tpr + precision)\n",
    "metrics['f1_score'] = f1_score\n",
    "\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These metrics basically mean two things: Our Bayesian spam/ham classifier correctly detects 94.5% of spam emails. On the other hand, out of the emails it predicts to be spam 3.5% are actually ham. While significantly better than guessing at random, this model's TPR is still far from [published models](https://plg.uwaterloo.ca/~gvcormac/spamcormack.pdf) with TPR ~99.93% and precision ~93.7%.\n",
    "\n",
    "To improve the models TPR, we will try adjusting the decision threshold and oversampling spam messages."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
